---
layout: post
title: Содержание курса Deep Learning in Natural Language Processing
---

Запись на курс [__здесь__](https://is.gd/NLP20171).

Семинары будут проводиться в следующем порядке:
1. Intro to NLP and Deep Learning
2. Simple Word Vector representations: word2vec, GloVe
3. Advanced word vector representations: language models, softmax, single layer networks
4. Neural Networks and backpropagation -- for named entity recognition
5. Project Advice, Neural Networks and Back-Prop (in full gory detail)
6. Practical tips: gradient checks, overfitting, regularization, activation functions, details
7. Recurrent neural networks -- for language modeling and other tasks
8. GRUs and LSTMs -- for machine translation
9. Convolutional neural networks -- for sentence classification
10. The future of Deep Learning for NLP: Dynamic Memory Networks

Syllabus по курсу возьмем от курса cs224d от Stanford University: [http://cs224d.stanford.edu/syllabus.html](http://cs224d.stanford.edu/syllabus.html)

Как и в прошлом году, курс будет состоять из просмотра лекций, заполнения квизов и выполнения домашних заданий, в том числе проекта. 

Видео-лекции будут использоваться за 2016-ый год: [youtube.com](https://www.youtube.com/watch?v=OQQ-W_63UgQ&list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6)
